# app.py
import streamlit as st
import pandas as pd
import numpy as np
import pickle
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
from alibi.explainers import AnchorTabular
import warnings

warnings.filterwarnings('ignore')

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="ASDé¢„æµ‹åˆ†æç³»ç»Ÿ",
    page_icon="ğŸ¥",
    layout="wide",
    initial_sidebar_state="expanded"
)


class ASDPredictor:
    """ASDé¢„æµ‹å™¨ç±»"""

    def __init__(self):
        self.aplr_models = None
        self.scalers = None
        self.feature_names = None
        self.categorical_features = None
        self.sample_data = None
        self.anchor_explainers = {}

    def load_models(self):
        """åŠ è½½é¢„è®­ç»ƒçš„æ¨¡å‹"""
        try:
            with open('models/aplr_models.pkl', 'rb') as f:
                self.aplr_models = pickle.load(f)

            with open('models/scalers.pkl', 'rb') as f:
                self.scalers = pickle.load(f)

            with open('models/feature_names.pkl', 'rb') as f:
                self.feature_names = pickle.load(f)

            with open('models/categorical_features.pkl', 'rb') as f:
                self.categorical_features = pickle.load(f)

            with open('models/sample_data.pkl', 'rb') as f:
                self.sample_data = pickle.load(f)

            return True
        except FileNotFoundError as e:
            st.error(f"æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°: {str(e)}")
            return False

    def setup_anchor_explainer(self, dataset_key):
        """è®¾ç½®é”šç‚¹è§£é‡Šå™¨"""
        if dataset_key in self.anchor_explainers:
            return self.anchor_explainers[dataset_key]

        try:
            # åˆ›å»ºé¢„æµ‹å‡½æ•°
            model = self.aplr_models[dataset_key]
            feature_names = self.feature_names[dataset_key]

            def predict_fn(x):
                if isinstance(x, np.ndarray):
                    x_df = pd.DataFrame(x, columns=feature_names)
                else:
                    x_df = x
                predictions = model.predict(x_df)
                return np.array([int(p) for p in predictions])

            # åˆ›å»ºé”šç‚¹è§£é‡Šå™¨
            anchor_explainer = AnchorTabular(
                predictor=predict_fn,
                feature_names=feature_names,
                categorical_names=self.categorical_features[dataset_key] if self.categorical_features[
                    dataset_key] else None
            )

            # ä½¿ç”¨ä¿å­˜çš„æ ·æœ¬æ•°æ®æ‹Ÿåˆ
            X_sample = self.sample_data[dataset_key]['X_sample']
            anchor_explainer.fit(X_sample, disc_perc=[25, 50, 75])

            self.anchor_explainers[dataset_key] = anchor_explainer
            return anchor_explainer

        except Exception as e:
            st.warning(f"é”šç‚¹è§£é‡Šå™¨è®¾ç½®å¤±è´¥: {str(e)}")
            return None

    def predict_sample(self, dataset_key, input_data):
        """å¯¹æ–°æ ·æœ¬è¿›è¡Œé¢„æµ‹å¹¶ç”Ÿæˆè§£é‡Š"""
        try:
            model = self.aplr_models[dataset_key]
            feature_names = self.feature_names[dataset_key]

            # åˆ›å»ºDataFrame
            input_df = pd.DataFrame([input_data], columns=feature_names)

            # APLRé¢„æµ‹
            prediction_raw = model.predict(input_df)
            prediction = int(prediction_raw[0])
            probabilities = model.predict_class_probabilities(input_df)[0]

            # é”šç‚¹è§£é‡Š
            anchor_exp = None
            anchor_explainer = self.setup_anchor_explainer(dataset_key)

            if anchor_explainer is not None:
                try:
                    anchor_exp = anchor_explainer.explain(
                        input_df.values[0],
                        threshold=0.85,
                        delta=0.1,
                        tau=0.15,
                        batch_size=100,
                        coverage_samples=500,
                        beam_size=2
                    )
                except Exception as e:
                    st.warning(f"é”šç‚¹è§£é‡Šç”Ÿæˆå¤±è´¥: {str(e)}")

            return prediction, probabilities, anchor_exp

        except Exception as e:
            st.error(f"é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            return None, None, None


@st.cache_resource
def load_predictor():
    """ç¼“å­˜åŠ è½½é¢„æµ‹å™¨"""
    predictor = ASDPredictor()
    if predictor.load_models():
        return predictor
    return None


def create_probability_chart(probabilities):
    """åˆ›å»ºæ¦‚ç‡å›¾è¡¨"""
    prob_asd = probabilities[1]
    prob_no_asd = probabilities[0]

    fig = go.Figure(data=[
        go.Bar(
            x=['ä¸å‘ç”ŸASD', 'å‘ç”ŸASD'],
            y=[prob_no_asd, prob_asd],
            marker_color=['green' if prob_no_asd > prob_asd else 'lightgreen',
                          'red' if prob_asd > prob_no_asd else 'lightcoral'],
            text=[f'{prob_no_asd:.1%}', f'{prob_asd:.1%}'],
            textposition='auto',
        )
    ])

    fig.update_layout(
        title="é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ",
        yaxis_title="æ¦‚ç‡",
        showlegend=False,
        height=400
    )
    return fig


def display_research_results(predictor, dataset_key, dataset_name):
    """æ˜¾ç¤ºç ”ç©¶ç»“æœ"""
    st.header(f"ğŸ“Š {dataset_name} æ•°æ®é›†ç ”ç©¶ç»“æœ")

    sample_data = predictor.sample_data[dataset_key]

    # æ˜¾ç¤ºæ•°æ®é›†åŸºæœ¬ä¿¡æ¯
    col1, col2, col3 = st.columns(3)

    with col1:
        st.metric("æ ·æœ¬æ•°é‡", sample_data['sample_size'])

    with col2:
        asd_count = sample_data['target_distribution'].get(1, 0)
        st.metric("ASDæ‚£è€…æ•°", asd_count)

    with col3:
        asd_rate = asd_count / sample_data['sample_size'] * 100
        st.metric("ASDå‘ç”Ÿç‡", f"{asd_rate:.1f}%")

    # ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯
    st.subheader("ğŸ“ˆ é‡è¦ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯")

    stats_df = pd.DataFrame(sample_data['feature_stats'])

    # æ˜¾ç¤ºéƒ¨åˆ†é‡è¦ç‰¹å¾çš„ç»Ÿè®¡ä¿¡æ¯
    important_features = ['Age', 'BMI', 'L3-4 EBQ', 'L5-S1 EBQ', 'L3-4 pfirrmann grade', 'L5-S1 pfirrmann grade']
    available_features = [f for f in important_features if f in stats_df.columns]

    if available_features:
        display_stats = stats_df[available_features].round(2)
        st.dataframe(display_stats, use_container_width=True)

    # æ¨¡å‹æ€§èƒ½ä¿¡æ¯
    st.subheader("ğŸ¯ æ¨¡å‹ä¿¡æ¯")

    col1, col2 = st.columns(2)
    with col1:
        st.info(f"""
        **âœ… APLRæ¨¡å‹**
        - æ¨¡å‹ç±»å‹: è‡ªåŠ¨åˆ†æ®µçº¿æ€§å›å½’
        - ç‰¹å¾æ•°é‡: {len(predictor.feature_names[dataset_key])}
        - è®­ç»ƒçŠ¶æ€: å·²å®Œæˆ
        """)

    with col2:
        st.info(f"""
        **âš“ è§£é‡Šèƒ½åŠ›**
        - å…¨å±€è§£é‡Š: æ”¯æŒ
        - å±€éƒ¨è§£é‡Š: æ”¯æŒ
        - é”šç‚¹è§£é‡Š: æ”¯æŒ
        """)

    # æ˜¾ç¤ºç‰¹å¾åˆ—è¡¨
    with st.expander("ğŸ“‹ æŸ¥çœ‹æ‰€æœ‰ç‰¹å¾åˆ—è¡¨"):
        feature_df = pd.DataFrame({
            'åºå·': range(1, len(predictor.feature_names[dataset_key]) + 1),
            'ç‰¹å¾åç§°': predictor.feature_names[dataset_key]
        })
        st.dataframe(feature_df, use_container_width=True)


def display_prediction_interface(predictor, dataset_key, dataset_name):
    """æ˜¾ç¤ºé¢„æµ‹ç•Œé¢"""
    st.header(f"ğŸ”® {dataset_name} æ–°æ ·æœ¬é¢„æµ‹")

    st.markdown("""
    è¯·è¾“å…¥æ‚£è€…çš„ç‰¹å¾å€¼ï¼Œç³»ç»Ÿå°†ä½¿ç”¨è®­ç»ƒå¥½çš„APLRæ¨¡å‹è¿›è¡ŒASDé£é™©é¢„æµ‹ï¼Œ
    å¹¶æä¾›é”šç‚¹è§£é‡Šåˆ†æã€‚
    """)

    # åˆ›å»ºè¾“å…¥è¡¨å•
    with st.form("prediction_form"):
        st.subheader("æ‚£è€…ç‰¹å¾è¾“å…¥")

        input_data = {}
        features = predictor.feature_names[dataset_key]
        stats = predictor.sample_data[dataset_key]['feature_stats']

        # åˆ†æˆå¤šåˆ—æ˜¾ç¤º
        cols = st.columns(3)
        col_idx = 0

        for feature in features:
            with cols[col_idx % 3]:
                # æ ¹æ®ç‰¹å¾åç§°åˆ¤æ–­è¾“å…¥ç±»å‹
                if feature.lower() in ['gender']:
                    input_data[feature] = st.selectbox(
                        feature,
                        options=[0, 1],
                        format_func=lambda x: 'å¥³æ€§' if x == 0 else 'ç”·æ€§',
                        key=f"{dataset_key}_{feature}"
                    )
                elif feature.lower() in ['hypertension', 'diabetes', 'smoking history', 'alcohol abuse']:
                    input_data[feature] = st.selectbox(
                        feature,
                        options=[0, 1],
                        format_func=lambda x: 'å¦' if x == 0 else 'æ˜¯',
                        key=f"{dataset_key}_{feature}"
                    )
                elif any(word in feature.lower() for word in
                         ['pfirrmann', 'grade', 'stenosis', 'modic', 'osteoarthritis']):
                    min_val = int(stats['min'][feature])
                    max_val = int(stats['max'][feature])
                    median_val = int(stats['median'][feature])
                    input_data[feature] = st.slider(
                        feature,
                        min_value=min_val,
                        max_value=max_val,
                        value=median_val,
                        key=f"{dataset_key}_{feature}"
                    )
                else:
                    # æ•°å€¼å‹ç‰¹å¾
                    min_val = float(stats['min'][feature])
                    max_val = float(stats['max'][feature])
                    mean_val = float(stats['mean'][feature])

                    input_data[feature] = st.number_input(
                        feature,
                        min_value=min_val,
                        max_value=max_val,
                        value=mean_val,
                        step=0.1 if max_val - min_val < 100 else 1.0,
                        key=f"{dataset_key}_{feature}"
                    )

            col_idx += 1

        submitted = st.form_submit_button("ğŸ” å¼€å§‹é¢„æµ‹", use_container_width=True)

    if submitted:
        with st.spinner("æ­£åœ¨è¿›è¡Œé¢„æµ‹å’Œç”Ÿæˆè§£é‡Š..."):
            # è¿›è¡Œé¢„æµ‹
            prediction, probabilities, anchor_exp = predictor.predict_sample(
                dataset_key, list(input_data.values())
            )

            if prediction is not None:
                # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
                st.success("âœ… é¢„æµ‹å®Œæˆï¼")

                col1, col2 = st.columns(2)

                with col1:
                    st.subheader("ğŸ¯ é¢„æµ‹ç»“æœ")

                    if prediction == 1:
                        st.error("âš ï¸ **é«˜é£é™©**ï¼šé¢„æµ‹å‘ç”ŸASD")
                    else:
                        st.success("âœ… **ä½é£é™©**ï¼šé¢„æµ‹ä¸å‘ç”ŸASD")

                    # æ¦‚ç‡æ˜¾ç¤º
                    prob_asd = probabilities[1]
                    prob_no_asd = probabilities[0]

                    col_a, col_b = st.columns(2)
                    with col_a:
                        st.metric("ASDå‘ç”Ÿæ¦‚ç‡", f"{prob_asd:.1%}")
                    with col_b:
                        st.metric("ä¸å‘ç”ŸASDæ¦‚ç‡", f"{prob_no_asd:.1%}")

                    # æ¦‚ç‡å›¾è¡¨
                    fig_prob = create_probability_chart(probabilities)
                    st.plotly_chart(fig_prob, use_container_width=True)

                with col2:
                    st.subheader("âš“ é”šç‚¹è§£é‡Š")

                    if anchor_exp is not None:
                        if len(anchor_exp.anchor) == 0:
                            st.info("ğŸ”„ **ç©ºé”šç‚¹**ï¼šæ¨¡å‹å¯¹è¯¥æ ·æœ¬çš„é¢„æµ‹éå¸¸ç¨³å®š")
                            st.markdown("""
                            **å«ä¹‰ï¼š** æ— è®ºå…¶ä»–ç‰¹å¾å¦‚ä½•å¾®è°ƒï¼Œé¢„æµ‹ç»“æœéƒ½ä¸ä¼šæ”¹å˜ã€‚
                            è¿™é€šå¸¸è¡¨æ˜è¯¥æ‚£è€…çš„é£é™©æ¨¡å¼éå¸¸æ˜ç¡®ã€‚
                            """)
                        else:
                            st.write("**ğŸ”‘ å…³é”®å†³ç­–è§„åˆ™ï¼š**")
                            for i, rule in enumerate(anchor_exp.anchor):
                                st.markdown(f"**{i + 1}.** `{rule}`")

                            col_a, col_b = st.columns(2)
                            with col_a:
                                st.metric("è§„åˆ™ç²¾ç¡®åº¦", f"{anchor_exp.precision:.1%}")
                            with col_b:
                                st.metric("è§„åˆ™è¦†ç›–ç‡", f"{anchor_exp.coverage:.1%}")

                            # è´¨é‡è¯„ä¼°
                            st.markdown("**ğŸ“Š è§„åˆ™è´¨é‡è¯„ä¼°ï¼š**")
                            if anchor_exp.precision >= 0.9:
                                st.success("âœ… ç²¾ç¡®åº¦ï¼šä¼˜ç§€ (â‰¥90%)")
                            elif anchor_exp.precision >= 0.8:
                                st.warning("âš ï¸ ç²¾ç¡®åº¦ï¼šè‰¯å¥½ (80-90%)")
                            else:
                                st.error("âŒ ç²¾ç¡®åº¦ï¼šéœ€è¦æ”¹è¿› (<80%)")

                            st.markdown(f"""
                            **ğŸ’¡ è§£é‡Šï¼š** å½“æ‚£è€…åŒæ—¶æ»¡è¶³ä¸Šè¿° {len(anchor_exp.anchor)} ä¸ªæ¡ä»¶æ—¶ï¼Œ
                            æ¨¡å‹æœ‰ {anchor_exp.precision:.1%} çš„æŠŠæ¡é¢„æµ‹ä¸º {'ASD' if prediction == 1 else 'æ— ASD'}ã€‚
                            è¿™ç§ç‰¹å¾ç»„åˆå‡ºç°åœ¨çº¦ {anchor_exp.coverage:.1%} çš„æ‚£è€…ä¸­ã€‚
                            """)
                    else:
                        st.warning("âš ï¸ æ— æ³•ç”Ÿæˆé”šç‚¹è§£é‡Š")

                # ç‰¹å¾å€¼æ€»ç»“
                st.subheader("ğŸ“‹ è¾“å…¥ç‰¹å¾æ€»ç»“")

                # åˆ›å»ºç‰¹å¾å€¼è¡¨æ ¼
                feature_summary = []
                for feature, value in input_data.items():
                    mean_val = stats['mean'][feature]
                    diff = value - mean_val

                    if abs(diff) < 0.01:
                        comparison = "â‰ˆ å¹³å‡å€¼"
                        color = "ğŸŸ¡"
                    elif diff > 0:
                        comparison = f"é«˜äºå¹³å‡ (+{diff:.2f})"
                        color = "ğŸ”´" if diff > stats['std'][feature] else "ğŸŸ "
                    else:
                        comparison = f"ä½äºå¹³å‡ ({diff:.2f})"
                        color = "ğŸ”µ" if abs(diff) > stats['std'][feature] else "ğŸŸ¢"

                    feature_summary.append({
                        'ç‰¹å¾åç§°': feature,
                        'è¾“å…¥å€¼': f"{value:.2f}" if isinstance(value, float) else str(value),
                        'å¹³å‡å€¼': f"{mean_val:.2f}",
                        'ä¸å¹³å‡å€¼æ¯”è¾ƒ': f"{color} {comparison}"
                    })

                summary_df = pd.DataFrame(feature_summary)
                st.dataframe(summary_df, use_container_width=True)

                # åŒ»å­¦å»ºè®®
                st.subheader("ğŸ’¡ ä¸ªæ€§åŒ–åŒ»å­¦å»ºè®®")

                if prediction == 1:
                    st.markdown("""
                    <div style="background-color: #ffebee; padding: 15px; border-radius: 10px; border-left: 5px solid #f44336;">
                    <h4 style="color: #d32f2f;">ğŸš¨ é«˜é£é™©æ‚£è€…ç®¡ç†å»ºè®®</h4>
                    <ul>
                    <li>ğŸ” <strong>å¯†åˆ‡ç›‘æ§ï¼š</strong> å»ºè®®3-6ä¸ªæœˆè¿›è¡Œå½±åƒå­¦å¤æŸ¥</li>
                    <li>ğŸƒâ€â™‚ï¸ <strong>åŠŸèƒ½é”»ç‚¼ï¼š</strong> åŠ å¼ºæ ¸å¿ƒè‚Œç¾¤å’Œè…°èƒŒè‚Œè®­ç»ƒ</li>
                    <li>âš–ï¸ <strong>ä½“é‡ç®¡ç†ï¼š</strong> æ§åˆ¶BMIï¼Œå‡å°‘è„ŠæŸ±è´Ÿè·</li>
                    <li>ğŸš­ <strong>ç”Ÿæ´»æ–¹å¼ï¼š</strong> æˆ’çƒŸé™é…’ï¼Œæ”¹å–„éª¨è´¨å¥åº·</li>
                    <li>ğŸ’Š <strong>è¯ç‰©å¹²é¢„ï¼š</strong> è€ƒè™‘æŠ—éª¨è´¨ç–æ¾æ²»ç–—</li>
                    <li>ğŸ©º <strong>éšè®¿è®¡åˆ’ï¼š</strong> åˆ¶å®šä¸ªæ€§åŒ–é•¿æœŸéšè®¿æ–¹æ¡ˆ</li>
                    </ul>
                    </div>
                    """, unsafe_allow_html=True)
                else:
                    st.markdown("""
                    <div style="background-color: #e8f5e8; padding: 15px; border-radius: 10px; border-left: 5px solid #4caf50;">
                    <h4 style="color: #388e3c;">âœ… ä½é£é™©æ‚£è€…ç»´æŠ¤å»ºè®®</h4>
                    <ul>
                    <li>âœ… <strong>ä¿æŒç°çŠ¶ï¼š</strong> ç»§ç»­ç»´æŒè‰¯å¥½çš„ç”Ÿæ´»ä¹ æƒ¯</li>
                    <li>ğŸƒâ€â™‚ï¸ <strong>é€‚åº¦è¿åŠ¨ï¼š</strong> è§„å¾‹è¿›è¡Œæœ‰æ°§å’ŒåŠ›é‡è®­ç»ƒ</li>
                    <li>ğŸ“… <strong>å¸¸è§„éšè®¿ï¼š</strong> å»ºè®®6-12ä¸ªæœˆå¤æŸ¥ä¸€æ¬¡</li>
                    <li>âš ï¸ <strong>ç—‡çŠ¶ç›‘æ§ï¼š</strong> æ³¨æ„è…°èƒŒéƒ¨ä¸é€‚ï¼ŒåŠæ—¶å°±åŒ»</li>
                    <li>ğŸ¥— <strong>è¥å…»è¡¥å……ï¼š</strong> ä¿è¯é’™è´¨å’Œç»´ç”Ÿç´ Dæ‘„å…¥</li>
                    <li>ğŸ˜Š <strong>å¿ƒç†å¥åº·ï¼š</strong> ä¿æŒç§¯æä¹è§‚çš„å¿ƒæ€</li>
                    </ul>
                    </div>
                    """, unsafe_allow_html=True)


def main():
    # åŠ è½½é¢„æµ‹å™¨
    predictor = load_predictor()

    if predictor is None:
        st.error("âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼è¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶å­˜åœ¨ã€‚")
        st.stop()

    # æ ‡é¢˜å’Œä»‹ç»
    st.title("ğŸ¥ ASDé¢„æµ‹åˆ†æç³»ç»Ÿ")
    st.markdown("""
    **ç›¸é‚»èŠ‚æ®µç—…å˜(Adjacent Segment Disease, ASD)é¢„æµ‹ç³»ç»Ÿ**

    åŸºäºè‡ªåŠ¨åˆ†æ®µçº¿æ€§å›å½’(APLR)æ¨¡å‹å’Œé”šç‚¹è§£é‡ŠæŠ€æœ¯ï¼Œä¸ºè„ŠæŸ±èåˆæœ¯åæ‚£è€…æä¾›ä¸ªæ€§åŒ–é£é™©è¯„ä¼°ã€‚
    """)
    st.markdown("---")

    # ä¾§è¾¹æ å¯¼èˆª
    st.sidebar.title("ğŸ§­ ç³»ç»Ÿå¯¼èˆª")
    st.sidebar.markdown("---")

    # é€‰æ‹©åˆ†æç±»å‹
    analysis_type = st.sidebar.selectbox(
        "ğŸ“Š é€‰æ‹©åŠŸèƒ½æ¨¡å—",
        ["ç ”ç©¶ç»“æœå±•ç¤º", "æ–°æ ·æœ¬é¢„æµ‹"],
        help="é€‰æ‹©è¦ä½¿ç”¨çš„åŠŸèƒ½æ¨¡å—"
    )

    # é€‰æ‹©æ•°æ®é›†
    dataset = st.sidebar.selectbox(
        "ğŸ¯ é€‰æ‹©é¢„æµ‹ç›®æ ‡",
        ["L3-4", "L5-S1"],
        format_func=lambda x: f"{x} èŠ‚æ®µASDé¢„æµ‹",
        help="é€‰æ‹©è¦åˆ†æçš„ç›¸é‚»èŠ‚æ®µ"
    )

    dataset_key = 'l34' if dataset == 'L3-4' else 'l5s1'

    # æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸ“‹ ç³»ç»Ÿä¿¡æ¯")
    st.sidebar.info(f"""
    **å½“å‰é…ç½®ï¼š**
    - ç›®æ ‡èŠ‚æ®µ: {dataset}
    - åŠŸèƒ½æ¨¡å—: {analysis_type}
    - æ¨¡å‹çŠ¶æ€: âœ… å·²åŠ è½½
    - è§£é‡ŠåŠŸèƒ½: âœ… å¯ç”¨
    """)

    # æ ¹æ®é€‰æ‹©æ˜¾ç¤ºç›¸åº”åŠŸèƒ½
    if analysis_type == "ç ”ç©¶ç»“æœå±•ç¤º":
        display_research_results(predictor, dataset_key, dataset)
    elif analysis_type == "æ–°æ ·æœ¬é¢„æµ‹":
        display_prediction_interface(predictor, dataset_key, dataset)

    # åº•éƒ¨ä¿¡æ¯
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #666; font-size: 12px;">
    <p>ğŸ”¬ åŸºäºå¯è§£é‡ŠAIæŠ€æœ¯ | âš•ï¸ ä»…ä¾›åŒ»å­¦ç ”ç©¶å‚è€ƒ | ğŸ¥ è¯·ç»“åˆä¸´åºŠå®é™…æƒ…å†µ</p>
    </div>
    """, unsafe_allow_html=True)


if __name__ == "__main__":
    main()